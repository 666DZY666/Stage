181108
keras版本的unet
https://blog.csdn.net/u012931582/article/details/70215756
倾斜书本的转正问题-透射变化+最小矩形检测
https://blog.csdn.net/mao_hui_fei/article/details/79729956
图像数据网络传输
https://blog.csdn.net/huhuang/article/details/54911982
python图像直方图
https://blog.csdn.net/yuyangyg/article/details/70857438
deeplabv3+训练笔记
https://blog.csdn.net/ncloveqy/article/details/82285106
https://python.ctolib.com/bonlime-keras-deeplab-v3-plus.html

深度学习论文路线学习笔记
https://github.com/SnailTyan/deep-learning-papers-translation
keras-yolo3-text
https://github.com/chineseocr/keras-yolo3-text
ICPR-2018——OCR笔记
https://blog.csdn.net/qq_14845119/article/details/82219246
SVHN
Text Recognition
https://bartzi.de/research/see

tensorflow版本STN——CNN——LSTM——CTC
https://github.com/Eric3911/STN_CNN_LSTM_CTC_TensorFlow

A文章来源：企鹅号 - CSIG文档图像分析与识别专委会
AAI 2018文档图像分析与识别相关论文选读
https://cloud.tencent.com/developer/news/154431
R2CNN
https://blog.csdn.net/u010183397/article/details/76473071
OCR系统论文
https://blog.csdn.net/jiachen0212/article/details/79498047
文本检测
https://zhuanlan.zhihu.com/p/37781277
https://github.com/bgshih/seglink
http://www.cnblogs.com/skyfsm/p/9776611.html
tensorflow不定长自然场景文本检测
https://blog.csdn.net/p312011150/article/details/82660072
文本检测
https://weibo.com/1560015614/GkLz1a4BH?type=comment
自然场景文本检测
https://blog.csdn.net/u011956004/article/details/79073282
Hypernet
https://segmentfault.com/a/1190000009030250
keras版本的Focal loss+Retinanet 
https://blog.csdn.net/u012426298/article/details/80450537
利用seglink训练自己的数据
https://blog.csdn.net/weixin_43122521/article/details/82558346
https://blog.csdn.net/u011440558/article/details/78564615
https://blog.csdn.net/jiachen0212/article/details/79471823?utm_source=blogxgwz1
DenseNet
tps://blog.csdn.net/qq_14845119/article/details/79272082
YOLT遥感图像识别
https://blog.csdn.net/bryant_meng/article/details/81284915
https://blog.csdn.net/jacke121/article/details/80531278
NasNet图像识别
https://blog.csdn.net/sparkexpert/article/details/79834704
遥感图像分割
基于segnet和Unet的语义分割
https://www.sohu.com/a/218292615_642762
Segnet训练自己的模型
https://blog.csdn.net/weixin_43122521/article/details/82558346
文本检测与OCR
https://weibo.com/1560015614/GkLz1a4BH?type=comment
https://zhuanlan.zhihu.com/p/37781277
https://weibo.com/1560015614/GkLz1a4BH?type=comment
https://zhuanlan.zhihu.com/p/37363942
tensorflow训练日志
https://www.urlteam.org/2017/09/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%AC%94%E8%AE%B0%E4%BA%8C%EF%BC%9Atensorflow%E5%B0%8F%E7%99%BD%E5%AE%9E%E8%B7%B5/
https://blog.csdn.net/asukasmallriver/article/details/78752178
https://www.urlteam.org/2017/09/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E7%AC%94%E8%AE%B0%E4%BA%8C%EF%BC%9Atensorflow%E5%B0%8F%E7%99%BD%E5%AE%9E%E8%B7%B5/
keras版本的GRU
https://blog.csdn.net/dcrmg/article/details/79306402
https://download.csdn.net/download/dcrmg/10248818
https://www.cnblogs.com/skyfsm/p/8029668.html
基于yolov3+CRNN的中文文字识别通用模型
https://swift.ctolib.com/article/comments/94721
动手学深度学习练习代码
https://github.com/SnailTyan/gluon-practice-code
opencv关键点检测
https://www.learnopencv.com/hand-keypoint-detection-using-deep-learning-and-opencv/
基于区域的全卷积神经网络
http://www.cnblogs.com/llfctt/p/9071889.html
图解CNN计算过程
https://blog.csdn.net/v_JULY_v/article/details/79434745?tdsourcetag=s_pcqq_aiomsg


图像旋转转正
import cv2	
import numpy as np
from PIL import Image
from skimage import transform
import matplotlib.pyplot as plt


def calc_length(point1, point2):
    x = (point1[0] - point2[0]) ** 2
    y = (point1[1] - point2[1]) ** 2
    return (x + y) ** 0.5

MIN_MATCH_COUNT = 10 
#标准的证件模板
dst_img = cv2.imread('C:/Users/Administrator/Desktop/1010test/1234567.jpg', 0)
#需要检测的证件读入路径
ori_img_ori = cv2.imread('C:/Users/Administrator/Desktop/1010test/123456.jpg', 1)
#使用SIFT检测角点
sift = cv2.xfeatures2d.SIFT_create()
# 获取关键点和描述符
kp1, des1 = sift.detectAndCompute(dst_img, None)
kp2, des2 = sift.detectAndCompute(ori_img_ori, None)

# 定义FLANN匹配器
index_params = dict(algorithm = 1, trees = 5)
search_params = dict(checks = 50)
flann = cv2.FlannBasedMatcher(index_params, search_params)
# 使用KNN算法匹配
matches = flann.knnMatch(des1,des2,k=2)

# 去除错误匹配
good = []
for m,n in matches:
    if m.distance < 0.9*n.distance:
        good.append(m)

# 单应性
print(len(good))
if len(good) > MIN_MATCH_COUNT:
    # 改变数组的表现形式，不改变数据内容，数据内容是每个关键点的坐标位置
    src_pts = np.float32([ kp1[m.queryIdx].pt for m in good ]).reshape(-1,1,2)
    dst_pts = np.float32([ kp2[m.trainIdx].pt for m in good ]).reshape(-1,1,2)
    # findHomography 函数是计算变换矩阵
    # 参数cv2.RANSAC是使用RANSAC算法寻找一个最佳单应性矩阵H，即返回值M
    # 返回值：M 为变换矩阵，mask是掩模
    M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)
    # ravel方法将数据降维处理，最后并转换成列表格式
    matchesMask = mask.ravel().tolist()
    # 获取img1的图像尺寸
    h,w = dst_img.shape
    # pts是图像img1的四个顶点
    pts = np.float32([[0,0],[0,h-1],[w-1,h-1],[w-1,0]]).reshape(-1,1,2)
    # 计算变换后的四个顶点坐标位置
    ori = cv2.perspectiveTransform(pts, M)

    dst = [(ele[0][0], ele[0][1]) for ele in ori]
    length_width = int(max(calc_length(dst[3], dst[0]), calc_length(dst[1], dst[2])))
    length_hight = int(max(calc_length(dst[0], dst[1]), calc_length(dst[2], dst[3])))
    tar = np.float32([[0,0],[length_hight,0],[length_hight,length_width], [0,length_width]])
    warp_matrix = cv2.getPerspectiveTransform(ori, tar)
    res = cv2.warpPerspective(ori_img_ori, warp_matrix, (length_hight, length_width))
    rot_img = transform.rotate(res[::-1,:], -90, resize=True)
    #img_new =cv2.resize(rot_img,(880,600),interpolation=cv2.INTER_CUBIC)
    result = cv2.imshow("WarpImg", rot_img)
    
else:
    print("Not enough matches are found - %d/%d") % (len(good),MIN_MATCH_COUNT)
    matchesMask = None
cv2.waitKey(0)





# -*- coding: utf-8 -*-
"""
Created on Fri Nov  2 11:39:31 2018

@author: Administrator
"""
#光斑检测问题
import cv2 as cv
import numpy as np

#全局阈值
def threshold_demo(image):
    gray = cv.cvtColor(image, cv.COLOR_RGB2GRAY)  #把输入图像灰度化
    #直接阈值化是对输入的单通道矩阵逐像素进行阈值分割。
    ret, binary = cv.threshold(gray, 0, 255, cv.THRESH_BINARY | cv.THRESH_TRIANGLE)
    print("threshold value %s"%ret)
    cv.namedWindow("binary0", cv.WINDOW_NORMAL)
    cv.imshow("binary0", binary)

#局部阈值
def local_threshold(image):
    gray = cv.cvtColor(image, cv.COLOR_RGB2GRAY)  #把输入图像灰度化
    #自适应阈值化能够根据图像不同区域亮度分布，改变阈值
    binary =  cv.adaptiveThreshold(gray, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C,cv.THRESH_BINARY, 25, 10)
    cv.namedWindow("binary1", cv.WINDOW_NORMAL)
    cv.imshow("binary1", binary)

#用户自己计算阈值
def custom_threshold(image):
    gray = cv.cvtColor(image, cv.COLOR_RGB2GRAY)  #把输入图像灰度化
    h, w =gray.shape[:2]
    m = np.reshape(gray, [1,w*h])
    mean = m.sum()/(w*h)
    print("mean:",mean)
    ret, binary =  cv.threshold(gray, mean, 255, cv.THRESH_BINARY)
    cv.namedWindow("binary2", cv.WINDOW_NORMAL)
    cv.imshow("binary2", binary)

src = cv.imread('C:/Users/Administrator/Desktop/1010test/1102/光斑检测/1.jpg')
cv.namedWindow('input_image', cv.WINDOW_NORMAL) #设置为WINDOW_NORMAL可以任意缩放
cv.imshow('input_image', src)
threshold_demo(src)
local_threshold(src)
custom_threshold(src)
cv.waitKey(0)
cv.destroyAllWindows()




取虫子
import cv2
import numpy as np


def get_image(path):
    #获取图片
    img=cv2.imread(path)
    gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)

    return img, gray

def Gaussian_Blur(gray):
    # 高斯去噪
    blurred = cv2.GaussianBlur(gray, (3, 3),0)

    return blurred

def Sobel_gradient(blurred):
    # 索比尔算子来计算x、y方向梯度
    gradX = cv2.Sobel(blurred, ddepth=cv2.CV_32F, dx=1, dy=0)
    gradY = cv2.Sobel(blurred, ddepth=cv2.CV_32F, dx=0, dy=1)

    gradient = cv2.subtract(gradX, gradY)
    gradient = cv2.convertScaleAbs(gradient)

    return gradX, gradY, gradient

def Thresh_and_blur(gradient):

    blurred = cv2.GaussianBlur(gradient, (9, 9),0)
    (_, thresh) = cv2.threshold(blurred, 90, 255, cv2.THRESH_BINARY)

    return thresh

def image_morphology(thresh):
    # 建立一个椭圆核函数
    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (25, 25))
    # 执行图像形态学, 细节直接查文档，很简单
    closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)
    closed = cv2.erode(closed, None, iterations=4)
    closed = cv2.dilate(closed, None, iterations=4)

    return closed

def findcnts_and_box_point(closed):
    # 这里opencv3返回的是三个参数
    (_, cnts, _) = cv2.findContours(closed.copy(),
        cv2.RETR_LIST,
        cv2.CHAIN_APPROX_SIMPLE)
    c = sorted(cnts, key=cv2.contourArea, reverse=True)[0]
    # compute the rotated bounding box of the largest contour
    rect = cv2.minAreaRect(c)
    box = np.int0(cv2.boxPoints(rect))

    return box

def drawcnts_and_cut(original_img, box):
    # 因为这个函数有极强的破坏性，所有需要在img.copy()上画
    # draw a bounding box arounded the detected barcode and display the image
    draw_img = cv2.drawContours(original_img.copy(), [box], -1, (0, 0, 255), 3)

    Xs = [i[0] for i in box]
    Ys = [i[1] for i in box]
    x1 = min(Xs)
    x2 = max(Xs)
    y1 = min(Ys)
    y2 = max(Ys)
    hight = y2 - y1
    width = x2 - x1
    crop_img = original_img[y1:y1+hight, x1:x1+width]

    return draw_img, crop_img

def walk():

    img_path = r'C:/Users/Administrator/Desktop/1010test/123456.jpg'
    save_path = r'C:/Users/Administrator/Desktop/1010test/1678_save.png'
    original_img, gray = get_image(img_path)
    blurred = Gaussian_Blur(gray)
    gradX, gradY, gradient = Sobel_gradient(blurred)
    thresh = Thresh_and_blur(gradient)
    closed = image_morphology(thresh)
    box = findcnts_and_box_point(closed)
    draw_img, crop_img = drawcnts_and_cut(original_img,box)

    # 暴力一点，把它们都显示出来看看

    cv2.imshow('original_img', original_img)
    cv2.imshow('blurred', blurred)
    cv2.imshow('gradX', gradX)
    cv2.imshow('gradY', gradY)
    cv2.imshow('final', gradient)
    cv2.imshow('thresh', thresh)
    cv2.imshow('closed', closed)
    cv2.imshow('draw_img', draw_img)
    cv2.imwrite('draw_img',draw_img)
    cv2.imshow('crop_img', crop_img)
    cv2.waitKey(20171219)
    cv2.imwrite(save_path, crop_img)

walk()



